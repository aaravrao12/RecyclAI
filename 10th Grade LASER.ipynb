{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMkSEEh5KKR8QG2/0MERDLc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import os\n","import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import time\n","from PIL import Image\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications import EfficientNetB0\n","from tensorflow.keras.layers import (\n","    Input, Dropout, GlobalAveragePooling2D, Dense, BatchNormalization,\n","    Reshape, multiply\n",")\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, Callback, LearningRateScheduler\n","from tensorflow.keras.regularizers import l2\n","from sklearn.utils.class_weight import compute_class_weight\n","\n","# PATHS\n","base_dir = \"/data\"\n","train_dir = os.path.join(base_dir, \"train\")\n","val_dir = os.path.join(base_dir, \"val\")\n","test_dir = os.path.join(base_dir, \"test\")\n","results_dir = \"/results\"\n","os.makedirs(results_dir, exist_ok=True)\n","\n","# REMOVE CORRUPT IMAGES\n","def is_image_corrupt(path):\n","    try:\n","        with Image.open(path) as img:\n","            img.convert('RGB')\n","            img.load()\n","        return False\n","    except Exception as e:\n","        print(f\"{path} is corrupt or unsupported: {e}\")\n","        return True\n","\n","def clean_directory(root_dir):\n","    corrupt_count = 0\n","    for subdir, _, files in os.walk(root_dir):\n","        for file in files:\n","            file_path = os.path.join(subdir, file)\n","            if is_image_corrupt(file_path):\n","                print(f\"Removing corrupt image: {file_path}\")\n","                os.remove(file_path)\n","                corrupt_count += 1\n","    print(f\"Done cleaning {root_dir}. {corrupt_count} corrupt images removed.\")\n","\n","clean_directory(train_dir)\n","clean_directory(val_dir)\n","clean_directory(test_dir)\n","\n","# PARAMETERS\n","img_size = (224, 224)\n","batch_size = 32\n","num_classes = 5\n","\n","# DATA AUGMENTATION\n","datagen_train = ImageDataGenerator(\n","    preprocessing_function=tf.keras.applications.efficientnet.preprocess_input,\n","    rotation_range=25,\n","    width_shift_range=0.25,\n","    height_shift_range=0.25,\n","    zoom_range=0.15,\n","    brightness_range=[0.8, 1.2],\n","    shear_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest'\n",")\n","datagen_val_test = ImageDataGenerator(\n","    preprocessing_function=tf.keras.applications.efficientnet.preprocess_input\n",")\n","\n","# LOAD DATA\n","train_gen = datagen_train.flow_from_directory(\n","    train_dir, target_size=img_size, batch_size=batch_size, class_mode='categorical'\n",")\n","val_gen = datagen_val_test.flow_from_directory(\n","    val_dir, target_size=img_size, batch_size=batch_size, class_mode='categorical'\n",")\n","test_gen = datagen_val_test.flow_from_directory(\n","    test_dir, target_size=img_size, batch_size=batch_size, class_mode='categorical', shuffle=False\n",")\n","\n","# CLASS WEIGHTS\n","class_weights = compute_class_weight(\n","    class_weight='balanced',\n","    classes=np.unique(train_gen.classes),\n","    y=train_gen.classes\n",")\n","class_weights_dict = dict(enumerate(class_weights))\n","\n","# CALLBACKS\n","def lr_scheduler(epoch, lr):\n","    return lr * 0.7 if epoch > 0 and epoch % 5 == 0 else lr\n","\n","class CustomLoggingCallback(Callback):\n","    def on_epoch_begin(self, epoch, logs=None):\n","        self.epoch_start_time = time.time()\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        duration = time.time() - self.epoch_start_time\n","        logs = logs or {}\n","        print(f\"Epoch {epoch+1}/{self.params['epochs']} - {duration:.0f}s - \"\n","              f\"accuracy: {logs.get('accuracy'):.4f} - loss: {logs.get('loss'):.4f} - \"\n","              f\"val_accuracy: {logs.get('val_accuracy'):.4f} - val_loss: {logs.get('val_loss'):.4f}\")\n","\n","early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","model_checkpoint = ModelCheckpoint(os.path.join(results_dir, 'best_model.keras'), save_best_only=True, monitor='val_loss', mode='min')\n","lr_schedule = LearningRateScheduler(lr_scheduler)\n","\n","# SE BLOCK DEFINITION\n","def se_block(input_tensor, reduction=16):\n","    channels = input_tensor.shape[-1]\n","    se = tf.keras.layers.GlobalAveragePooling2D()(input_tensor)\n","    se = Reshape((1, 1, channels))(se)\n","    se = Dense(channels // reduction, activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n","    se = Dense(channels, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n","    x = multiply([input_tensor, se])\n","    return x\n","\n","# MODEL WITH SE BLOCK\n","input_tensor = Input(shape=(224, 224, 3))\n","base_model = EfficientNetB0(weights='imagenet', include_top=False, input_tensor=input_tensor)\n","for layer in base_model.layers[:-30]:\n","    layer.trainable = False\n","\n","x = base_model.output\n","x = se_block(x)  # SE block is added\n","x = Dropout(0.3)(x)\n","x = GlobalAveragePooling2D()(x)\n","x = Dense(256, activation='relu', kernel_regularizer=l2(0.001))(x)\n","x = BatchNormalization()(x)\n","x = Dropout(0.5)(x)\n","output = Dense(num_classes, activation='softmax', dtype='float32')(x)\n","\n","model = Model(inputs=base_model.input, outputs=output)\n","\n","model.compile(\n","    optimizer=Adam(learning_rate=0.001),\n","    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n","    metrics=['accuracy']\n",")\n","\n","# TRAIN\n","history = model.fit(\n","    train_gen,\n","    validation_data=val_gen,\n","    epochs=10,\n","    callbacks=[early_stopping, model_checkpoint, lr_schedule, CustomLoggingCallback()],\n","    class_weight=class_weights_dict\n",")\n","\n","# CONVERT TO TFLITE\n","converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","tflite_model = converter.convert()\n","\n","tflite_model_path = os.path.join(results_dir, \"waste_classifier_se.tflite\")\n","with open(tflite_model_path, \"wb\") as f:\n","    f.write(tflite_model)\n","\n","print(f\"TFLite model saved to: {tflite_model_path}\")\n"],"metadata":{"id":"JpLL3L90f-yV"},"execution_count":null,"outputs":[]}]}